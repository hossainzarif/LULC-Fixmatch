{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7799e7d1-4fc3-41c3-852b-c7fae96af05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageEnhance\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee047ce5-62dc-4da9-af17-15276d020f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fc2c9f-b1fc-4745-9039-d70bd163a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\2021\\2학기 수업\\CV\\SSL\n"
     ]
    }
   ],
   "source": [
    "# root dir\n",
    "os.chdir(\"D:/2021/2학기 수업/CV/SSL/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa51bad-a847-45f6-b227-308d1f8e36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = 'checkpoint/model_best.pth.tar'\n",
    "save = 'result/result.json'\n",
    "\n",
    "eval_steps = 2**10\n",
    "total_steps = 2**20\n",
    "batch_size = 64\n",
    "lr = 0.03\n",
    "weight_decay = 0.0005\n",
    "exp_mov_avg_decay = 0.999\n",
    "mu = 7\n",
    "lambda_u = 1\n",
    "threshold = 0.95\n",
    "\n",
    "num_class = 10\n",
    "num_labeled_data = 40\n",
    "\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2471, 0.2435, 0.2616)\n",
    "\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cedb139-e96a-40a0-a244-47233b609f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETER_MAX = 10\n",
    "\n",
    "def _float_parameter(v, max_v):\n",
    "    return float(v) * max_v / PARAMETER_MAX\n",
    "\n",
    "def _int_parameter(v, max_v):\n",
    "    return int(v * max_v / PARAMETER_MAX)\n",
    "\n",
    "def AutoContrast(img, **kwarg):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "def Brightness(img, v, max_v, bias = 0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "def Color(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Contrast(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Cutout(img, v, max_v, bias=0):\n",
    "    if v == 0:\n",
    "        return img\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    v = int(v * min(img.size))\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v, **kwarg):\n",
    "    w, h = img.size\n",
    "    x0 = np.random.uniform(0, w)\n",
    "    y0 = np.random.uniform(0, h)\n",
    "    x0 = int(max(0, x0 - v / 2.))\n",
    "    y0 = int(max(0, y0 - v / 2.))\n",
    "    x1 = int(min(w, x0 + v))\n",
    "    y1 = int(min(h, y0 + v))\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    # gray\n",
    "    color = (127, 127, 127)\n",
    "    img = img.copy()\n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def Equalize(img, **kwarg):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Identity(img, **kwarg):\n",
    "    return img\n",
    "\n",
    "\n",
    "def Invert(img, **kwarg):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Posterize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Rotate(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def ShearX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def Solarize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.solarize(img, 256 - v)\n",
    "\n",
    "\n",
    "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    img_np = np.array(img).astype(np.int)\n",
    "    img_np = img_np + v\n",
    "    img_np = np.clip(img_np, 0, 255)\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    img = Image.fromarray(img_np)\n",
    "    return PIL.ImageOps.solarize(img, threshold)\n",
    "\n",
    "\n",
    "def TranslateX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[0])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[1])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "def fixMatchAugPool():\n",
    "    augs = [(AutoContrast, None, None),\n",
    "            (Brightness, 0.9, 0.05),\n",
    "            (Color, 0.9, 0.05),\n",
    "            (Contrast, 0.9, 0.05),\n",
    "            (Equalize, None, None),\n",
    "            (Identity, None, None),\n",
    "            (Posterize, 4, 4),\n",
    "            (Rotate, 30, 0),\n",
    "            (Sharpness, 0.9, 0.05),\n",
    "            (ShearX, 0.3, 0),\n",
    "            (ShearY, 0.3, 0),\n",
    "            (Solarize, 256, 0),\n",
    "            (TranslateX, 0.3, 0),\n",
    "            (TranslateY, 0.3, 0)]\n",
    "    return augs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69147066-40b5-401c-b81d-d540cb9bb8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandAugmentMC(object):\n",
    "    def __init__(self, n, m):\n",
    "        assert n >= 1\n",
    "        assert 1 <= m <= 10\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.augment_pool = fixMatchAugPool()\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        ops = random.choices(self.augment_pool, k = self.n)\n",
    "        for op, max_v, bias in ops:\n",
    "            v = np.random.randint(1, self.m)\n",
    "            if random.random() < 0.5:\n",
    "                img = op(img, v = v, max_v = max_v, bias = bias)\n",
    "        img = CutoutAbs(img, int(32*0.5))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6135e980-71a8-4e7f-a424-71e0a2a4a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformFixMatch(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.weak = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size = 32,\n",
    "                                  padding = int(32 * 0.125),\n",
    "                                  padding_mode = 'reflect')])\n",
    "        \n",
    "        self.strong = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size = 32,\n",
    "                                  padding = int(32 * 0.125),\n",
    "                                  padding_mode = 'reflect'),\n",
    "            RandAugmentMC(n = 2, m = 10)])\n",
    "        \n",
    "        self.normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = mean, std = std)])\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        weak = self.weak(x)\n",
    "        strong = self.strong(x)\n",
    "        return self.normalize(weak), self.normalize(strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8234e50e-3d53-4068-a91f-2e98386e5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'\n",
    "labeled_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(size = 32, padding = int(32 * 0.125), padding_mode = 'reflect'),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = cifar10_mean, std = cifar10_std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = cifar10_mean, std = cifar10_std)\n",
    "])\n",
    "\n",
    "full_dataset = datasets.CIFAR10(root, train = True, download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80752a08-400c-4152-8e5a-8594044b30de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "65560 50000\n"
     ]
    }
   ],
   "source": [
    "label_per_class = num_labeled_data // num_class\n",
    "labels = np.array(full_dataset.targets)\n",
    "train_labeled_idxs = []\n",
    "train_unlabeled_idxs = np.array(range(len(labels)))\n",
    "for i in range(num_class):\n",
    "    idx = np.where(labels == i)[0]\n",
    "    idx = np.random.choice(idx, label_per_class, False)\n",
    "    train_labeled_idxs.extend(idx)\n",
    "train_labeled_idxs = np.array(train_labeled_idxs)\n",
    "print(len(train_labeled_idxs))\n",
    "\n",
    "num_expand_x = math.ceil(batch_size * eval_steps / num_labeled_data)\n",
    "train_labeled_idxs = np.hstack([train_labeled_idxs for _ in range(num_expand_x)])\n",
    "print(len(train_labeled_idxs), len(train_unlabeled_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12833a65-cabb-4894-bddb-5ce5c9ffda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10SSL(datasets.CIFAR10):\n",
    "    def __init__(self, root, idxs, train = True, transform = None, target_transform = None, download = False):\n",
    "        super().__init__(root, train = train, transform = transform, target_transform = target_transform, download = download)\n",
    "        if idxs is not None:\n",
    "            self.data = self.data[idxs]\n",
    "            self.targets = np.array(self.targets)[idxs]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, target = self.data[idx], self.targets[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d1daa3-2f98-4b0b-8831-c2286dca3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_dataset = Cifar10SSL(root, train_labeled_idxs, train=True, transform=labeled_transform)\n",
    "train_unlabeled_dataset = Cifar10SSL(root, train_unlabeled_idxs, train=True,\n",
    "                                     transform=TransformFixMatch(mean = cifar10_mean, std = cifar10_std))\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root, train = False, transform = test_transform, download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c785c399-b884-47c5-a2ef-92d88bccdc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_trainloader = DataLoader(train_labeled_dataset,\n",
    "                                 sampler = RandomSampler(train_labeled_dataset),\n",
    "                                 batch_size = batch_size,\n",
    "                                 drop_last = True)\n",
    "unlabeled_trainloader = DataLoader(train_unlabeled_dataset,\n",
    "                                 sampler = RandomSampler(train_unlabeled_dataset),\n",
    "                                 batch_size = batch_size * mu,\n",
    "                                 drop_last = True)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         sampler = SequentialSampler(test_dataset),\n",
    "                         batch_size = batch_size)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f6d6413-cd89-477e-b5ee-c35751f9fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRNBasicBlock(torch.nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, drop_rate = 0.0, activate_before_residual = False):\n",
    "        super(WRNBasicBlock, self).__init__()      \n",
    "        self.bn1 = torch.nn.BatchNorm2d(in_planes, momentum = 0.001)\n",
    "        self.relu1 = torch.nn.LeakyReLU(negative_slope = 0.1, inplace = True)\n",
    "        self.conv1 = torch.nn.Conv2d(in_planes, out_planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "        \n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_planes, momentum = 0.001)\n",
    "        self.relu2 = torch.nn.LeakyReLU(negative_slope = 0.1, inplace = True)\n",
    "        self.conv2 = torch.nn.Conv2d(out_planes, out_planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and torch.nn.Conv2d(in_planes, out_planes, kernel_size = 1, stride = stride,\n",
    "                                                                padding = 0, bias = False) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual == True:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        \n",
    "        if self.drop_rate > 0:\n",
    "            out = F.dropout(out, p=self.drop_rate, training = self.training)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d859ea99-ec3a-4dfa-a246-5914f709e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRNNetworkBlock(torch.nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, drop_rate = 0.0, activate_before_residual = False):\n",
    "        super(WRNNetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(\n",
    "            block, in_planes, out_planes, nb_layers, stride, drop_rate, activate_before_residual)\n",
    "        \n",
    "    def _make_layer(\n",
    "            self, block, in_planes, out_planes, nb_layers, stride, drop_rate, activate_before_residual):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes,\n",
    "                                i == 0 and stride or 1, drop_rate, activate_before_residual))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aae2736-0c75-41ea-8ce0-6b351a4fb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRN(torch.nn.Module):\n",
    "    def __init__(self, num_classes, depth = 28, widen_factor = 2, drop_rate = 0.0):\n",
    "        super(WRN, self).__init__()\n",
    "        channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
    "        \n",
    "        # basic block의 depth = 6, basic block 외의 depth = 4\n",
    "        # 따라서 depth - 4 의 값은 6의 배수여야 함.\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        \n",
    "        n = (depth - 4) / 6\n",
    "        block = WRNBasicBlock\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, channels[0], kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        \n",
    "        self.block1 = WRNNetworkBlock(\n",
    "            n, channels[0], channels[1], block, 1, drop_rate, activate_before_residual = True)\n",
    "        \n",
    "        self.block2 = WRNNetworkBlock(\n",
    "            n, channels[1], channels[2], block, 2, drop_rate)\n",
    "        \n",
    "        self.block3 = WRNNetworkBlock(\n",
    "            n, channels[2], channels[3], block, 2, drop_rate)\n",
    "        \n",
    "        self.bn = torch.nn.BatchNorm2d(channels[3], momentum = 0.001)\n",
    "        self.relu = torch.nn.LeakyReLU(negative_slope = 0.1, inplace = True)\n",
    "        self.fc = torch.nn.Linear(channels[3], num_classes)\n",
    "        self.channels = channels[3]\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity = 'leaky_relu')\n",
    "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "                torch.nn.init.constant_(m.weight, 1.0)\n",
    "                torch.nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(m.weight)\n",
    "                torch.nn.init.constant_(m.bias, 0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn(out))\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(-1, self.channels)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7777fcfc-cd22-48ce-9379-caacd0f0b608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WRN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): WRNNetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): WRNNetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block3): WRNNetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): WRNBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WRN(num_class)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a807e5f7-62be-4534-a021-11be785c951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'bn']\n",
    "grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = optim.SGD(grouped_parameters, lr=lr, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b08a465-10c2-42d4-9624-4693702e8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosScheduleWithWarmup(optimizer,\n",
    "                             num_warmup_steps,\n",
    "                             num_training_steps,\n",
    "                             num_cycles = 7./16.,\n",
    "                             last_epoch = -1):\n",
    "    def _lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        no_progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
    "    \n",
    "    return LambdaLR(optimizer, _lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953f2e9e-eafb-42d6-8ed4-df9c7909030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = math.ceil(total_steps / eval_steps)\n",
    "scheduler = getCosScheduleWithWarmup(optimizer, 0, total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204751fe-0046-4d39-93b2-92dcf1517ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential moving avg\n",
    "class ModelEMA(object):\n",
    "    def __init__(self, model, decay):\n",
    "        self.ema = deepcopy(model)\n",
    "        self.ema.to(device)\n",
    "        self.ema.eval()\n",
    "        self.decay = decay\n",
    "        self.ema_has_module = hasattr(self.ema, 'module')\n",
    "        self.param_keys = [k for k, _ in self.ema.named_parameters()]\n",
    "        self.buffer_keys = [k for k, _ in self.ema.named_buffers()]\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "    \n",
    "    def update(self, model):\n",
    "        needs_module = hasattr(model, 'module') and not self.ema_has_module\n",
    "        with torch.no_grad():\n",
    "            msd = model.state_dict()\n",
    "            esd = self.ema.state_dict()\n",
    "            for k in self.param_keys:\n",
    "                if needs_module:\n",
    "                    j = 'module.' + k\n",
    "                else:\n",
    "                    j = k\n",
    "                model_v = msd[j].detach()\n",
    "                ema_v = esd[k]\n",
    "                esd[k].copy_(ema_v * self.decay + (1. - self.decay) * model_v)\n",
    "\n",
    "            for k in self.buffer_keys:\n",
    "                if needs_module:\n",
    "                    j = 'module.' + k\n",
    "                else:\n",
    "                    j = k\n",
    "                esd[k].copy_(msd[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f195b88-2748-40b2-8605-d867bc5852e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_model = ModelEMA(model, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d9de000-c8a3-4a32-b3e1-3673902c4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "if resume:\n",
    "    assert os.path.isfile(resume), \"Error: no checkpoint directory found!\"\n",
    "    out = os.path.dirname(resume)\n",
    "    checkpoint = torch.load(resume)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    ema_model.ema.load_state_dict(checkpoint['ema_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1dee509-4e82-4d1f-bc49-f107ac58cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f7755bc-3f86-4e4a-8774-a9b7aef6a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    predlist = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            model.eval()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, pred = outputs.topk(1,1,True,True)\n",
    "            predlist+=pred.cpu()\n",
    "    \n",
    "    pred_dict = {idx:p_i.item() for idx, p_i in enumerate(predlist)}\n",
    "    with open(save, 'w') as f:\n",
    "        json.dump(pred_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a1d3b49-0cf8-4d84-ad17-14690a1ab53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ed79e-d8b3-4050-8599-c09f1e48da38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
